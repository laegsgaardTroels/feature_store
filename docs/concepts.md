## Concepts

Below are the most important concepts related to a feature store. For more concepts see the documentations in the [Related Projected](related_projects.md) e.g. [Hopsworks Concepts Documentation](https://www.hopsworks.ai/mlops-dictionary?utm_source=fs.org&utm_medium=web), [Databricks Concepts Documentation](https://docs.databricks.com/en/machine-learning/feature-store/concepts.html), [Feast Concepts Documentation](https://docs.feast.dev/master/getting-started/concepts) etc.

### Feature

A feature is a vector $X=(X_1,X_2,\dots,X_p)$ of real numbers in the [The Supervised Learning Problem](#the-supervised-learning-problem).

### Offline store

A storage used for feature lookups during analysis and model training. Conceptually all rows.

### Online store

A storage used for features lookup during real-time model inference. Conceptually the single latest row.

### Point-in-time lookup

Feature values are matched based on primary keys and a `timestamp` key, using an `AS OF` join. The `AS OF` join ensures that the most recent value of the feature at the time of the `timestamp` is used in the training set.

### Backfill

Backfilling is the process of recomputing datasets from raw, historical data. For reusable features in a feature store, backfilling involves running a feature pipeline with historical data to populate the feature store.

### Data Leakage

The use of information in the model training process which would not be expected to be available at prediction time / inference.

### Directed asyclic graph (DAG)

A list of tasks forms a DAG and a DAG forms a list of tasks.

### Limitation

Only use a limited number of rows for computation, inserts, updates, upserts etc.

### The Supervised Learning Problem

Standard working assumption in supervised learning is that the mechanish that generates the data can be desribed as

$$
\begin{aligned}
Y &= f(X) + \epsilon && \text{[Regression]} \\
P(Y=1 \vert X) &= f(X)  && \text{[Binary Classification]}
\end{aligned}
$$

$f$ is a function, $X=(X_1,X_2,\dots,X_p)$ is a vector of inputs/features, $Y$ is the labels/output/response and $\epsilon$ is random noise.

**General Problem**: We are interested in estimating the function $f$ using a dataset consisting of labels: $Y$ and features: $X$, that are generated by the same mechanish described above.

